<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>Lee Tzu Lam — ACHCI Lab</title>
<meta name="description" content="Lee Tzu Lam — Founder of ACHCI Lab. Research in Affective Computing, Brain-Inspired Cognitive Decision-Making, and HCI."/>
<meta property="og:title" content="Lee Tzu Lam — ACHCI Lab"/>
<meta property="og:description" content="Founder of ACHCI Lab. Affective Computing · Brain-Inspired Cognition · HCI"/>
<meta property="og:type" content="website"/>
<meta property="og:url" content="https://lixeeone.github.io"/>
<meta property="og:image" content="assets/self.jpg"/>
<link rel="icon" href="assets/logo.png"/>
<script src="https://cdn.tailwindcss.com"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&family=EB+Garamond:wght@500;600;700&display=swap" rel="stylesheet">
<style>
  html{scroll-behavior:smooth}
  body{background:#fff;color:#111827;font-family:Inter,ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,"Helvetica Neue",Arial}
  .glass{background:rgba(255,255,255,.7);backdrop-filter:blur(8px)}
  .section{border-top:1px solid #e5e7eb}
  .brand-gradient{background:linear-gradient(90deg,#0ea5e9,#6366f1,#ec4899);-webkit-background-clip:text;background-clip:text;color:transparent}
  .kicker{letter-spacing:.18em;text-transform:uppercase;font-size:.72rem;color:#6b7280}
  .rule{height:1px;flex:1;background:linear-gradient(90deg,#e5e7eb,transparent)}
  .section-hd{display:flex;align-items:center;gap:.9rem}
  .h2{font-size:1.5rem;font-weight:700;letter-spacing:.2px}
  .muted{color:#6b7280}
  .lead{color:#4b5563;line-height:1.7}

  /* 背景柔光网格（保持） */
  .moving-gradient::before{
    content:"";position:absolute;inset:0;z-index:0;opacity:.6;background:
      radial-gradient(60% 50% at 50% 10%,rgba(99,102,241,.20),transparent 60%),
      radial-gradient(40% 30% at 80% 0%,rgba(14,165,233,.18),transparent 60%),
      radial-gradient(30% 25% at 20% 0%,rgba(236,72,153,.16),transparent 60%);
    animation:floatGrad 18s ease-in-out infinite alternate;pointer-events:none
  }
  @keyframes floatGrad{0%{transform:translateY(-3%) scale(1)}100%{transform:translateY(3%) scale(1.05)}}
  #particles{position:absolute;inset:0;z-index:1;pointer-events:none;opacity:.55}
  .hero-inner{position:relative;z-index:2}

  /* Hero 大引号 + 起伏排版 */
  .claim{
    font-family:"EB Garamond",ui-serif,Georgia,"Times New Roman",serif;
    font-size:clamp(1.25rem,2.2vw,1.6rem);
    line-height:1.95;
    letter-spacing:.01em;
    word-spacing:.08em;         /* 单词间适度留白 */
    color:#1f2937;
  }
  .claim span.bump{display:inline-block;transform:translateY(-.07em)}
  .claim span.dip{display:inline-block;transform:translateY(.08em)}
  .claim-wrap{position:relative;padding-left:2.3rem;padding-right:2.3rem}
  .claim-wrap::before,.claim-wrap::after{
    content:"“";position:absolute;top:-.35rem;font-family:"EB Garamond",serif;
    font-weight:700;font-size:4.2rem;line-height:1;color:#9aa0b1;opacity:.25
  }
  .claim-wrap::before{left:.1rem}
  .claim-wrap::after{content:"”";right:.1rem;top:auto;bottom:-.6rem;opacity:.22}

  /* 右侧竖排水印 */
  .motto{
    position:fixed;right:10px;top:50%;transform:translateY(-50%) rotate(90deg);
    font-family:"EB Garamond",serif;font-weight:700;
    font-size:clamp(28px,10vw,90px);letter-spacing:.02em;
    background:linear-gradient(90deg,#0ea5e9,#6366f1);-webkit-background-clip:text;background-clip:text;color:transparent;
    opacity:.10;user-select:none;pointer-events:none;z-index:3;white-space:nowrap
  }

  /* 教育校徽容器（透明图不做过度处理，仅统一大小） */
  .crest-wrap{width:48px;height:48px;border-radius:11px;display:flex;align-items:center;justify-content:center}
  .crest{max-width:100%;max-height:100%;object-fit:contain}

  /* 论文卡片 */
  .paper{background:#f8f9fb;border:1px solid #e5e7eb;border-radius:12px}
  .paper:hover{box-shadow:0 18px 44px rgba(2,6,23,.08);transform:translateY(-2px);transition:all .25s}

  /* 时间轴 */
  .timeline{position:relative;padding-left:22px}
  .timeline::before{content:"";position:absolute;left:8px;top:6px;bottom:6px;width:2px;background:#e5e7eb}
  .t-item{position:relative;padding:18px;border:1px solid #ececec;border-radius:14px;background:#fff}
  .t-item+.t-item{margin-top:14px}
  .t-dot{position:absolute;left:-22px;top:22px;width:10px;height:10px;border-radius:999px;background:#6366f1;box-shadow:0 0 0 4px #eef2ff}
  .t-hd{display:flex;align-items:flex-start;justify-content:space-between;gap:1rem}
  .t-role{font-weight:600}.t-where{color:#6b7280;font-size:.92rem}.t-when{color:#6b7280;font-size:.9rem;white-space:nowrap}
  .t-body{margin-top:.5rem;color:#4b5563;font-size:.95rem;line-height:1.7}
  .pill{display:inline-block;padding:.25rem .55rem;border:1px solid #e6e6ef;border-radius:999px;font-size:.78rem;color:#555;background:#fbfbfe;margin-right:.35rem}

  /* Future Map 卡片与画布（修复遮挡 & 全显） */
  #future-card{position:relative;border:1px solid #ececf2;background:linear-gradient(180deg,#fafafa,#ffffff);border-radius:16px;overflow:hidden;min-height:520px}
  #futureCanvas{position:absolute;inset:0;display:block}
  #future-tip{position:absolute;max-width:440px;font-size:.86rem;line-height:1.55;background:#ffffffe6;border:1px solid #e6e6ef;padding:.6rem .7rem;border-radius:.75rem;backdrop-filter:blur(6px);box-shadow:0 10px 24px rgba(2,6,23,.08);display:none;pointer-events:none;z-index:2}

  /* 顶部导航 Logo 放大 1.5× */
  .brand-logo{width:72px;height:72px} /* 原 ~48px 的 1.5 倍 */

  /* 按钮图标统一尺寸 */
  .btn-ic{width:18px;height:18px;display:inline-block}
</style>
</head>
<body class="antialiased">

<!-- 固定竖排水印 -->
<div class="motto">AI4Science, Science2AI</div>

<!-- 顶部导航 -->
<header class="sticky top-0 z-50 border-b border-zinc-200 glass">
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 h-16 flex items-center justify-between">
    <a href="#home" class="flex items-center gap-3">
      <img src="assets/logo.png" alt="ACHCI Lab logo" class="brand-logo rounded-lg object-contain" onerror="this.src='https://github.com/Lixeeone.png'"/>
      <span class="font-semibold brand-gradient text-lg">ACHCI Lab</span>
    </a>
    <nav class="hidden md:flex items-center gap-8 text-sm text-zinc-700">
      <a href="#research" class="hover:opacity-80">Research</a>
      <a href="#highlights" class="hover:opacity-80">Future</a>
      <a href="#publications" class="hover:opacity-80">Publications</a>
      <a href="#experience" class="hover:opacity-80">Experience</a>
      <a href="#education" class="hover:opacity-80">Education</a>
      <a href="#contact" class="hover:opacity-80">Contact</a>
    </nav>
  </div>
</header>

<!-- Hero -->
<section id="home" class="relative overflow-hidden moving-gradient">
  <canvas id="particles" aria-hidden="true"></canvas>
  <div class="hero-inner relative max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-16 sm:py-24">
    <div class="grid md:grid-cols-5 gap-10 items-center">
      <div class="md:col-span-3">
        <p class="kicker">FOUNDER, ACHCI LAB</p>
        <h1 class="mt-2 text-5xl font-extrabold leading-tight">Lee Tzu Lam</h1>

        <!-- 起伏式静态排版 + 大引号 -->
        <div class="claim-wrap mt-5">
          <p class="claim">
            My research spans <span class="bump">Affective Computing</span>, <span class="dip">Brain-Inspired Cognitive Decision-Making</span>, and <span class="bump">Human-Computer Interaction</span>. I build reproducible AI systems and multimodal models that understand and respond to human emotion.
          </p>
        </div>

        <!-- 社交按钮（带精准图标） -->
        <div class="mt-6 flex flex-wrap gap-3">
          <a class="inline-flex items-center gap-2 rounded-2xl border border-zinc-300 px-4 py-2 text-sm hover:bg-zinc-50" href="https://github.com/Lixeeone" target="_blank" rel="noopener">
            <svg class="btn-ic" viewBox="0 0 16 16" fill="currentColor" aria-hidden="true"><path d="M8 .2A7.8 7.8 0 0 0 5.5 15.4c.4.1.6-.2.6-.4v-1.5c-2.4.5-2.9-1.1-2.9-1.1-.4-1-.9-1.3-.9-1.3-.8-.6.1-.6.1-.6 1 .1 1.6 1 1.6 1 .8 1.5 2.2 1.1 2.7.8.1-.6.3-1.1.6-1.3-1.9-.2-3.9-1-3.9-4.3 0-.9.3-1.6.8-2.2 0-.2-.3-1 .1-2.1 0 0 .7-.2 2.2.8.6-.2 1.2-.2 1.8-.2s1.2 0 1.8.2c1.5-1 2.2-.8 2.2-.8.4 1.1.1 1.9.1 2.1.5.6.8 1.3.8 2.2 0 3.3-2 4-3.9 4.3.3.2.6.7.6 1.5v2.2c0 .2.2.5.6.4A7.8 7.8 0 0 0 8 .2z"/></svg>
            GitHub
          </a>
          <a class="inline-flex items-center gap-2 rounded-2xl border border-zinc-300 px-4 py-2 text-sm hover:bg-zinc-50" href="https://huggingface.co/Lixeeone" target="_blank" rel="noopener">
            <img class="btn-ic" src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face"/>
            Hugging Face
          </a>
          <a class="inline-flex items-center gap-2 rounded-2xl border border-zinc-300 px-4 py-2 text-sm hover:bg-zinc-50" href="https://orcid.org/0009-0002-4314-455X" target="_blank" rel="noopener">
            <svg class="btn-ic" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true"><path d="M12 1.5a10.5 10.5 0 1 0 0 21 10.5 10.5 0 0 0 0-21Zm-2.7 5.2h1.3v10.6H9.3V6.7Zm3.7 0c2.5 0 4.3 1.8 4.3 4.4s-1.8 4.4-4.3 4.4h-2V6.7h2Zm0 1.3h-.7v6.2h.7c1.9 0 3.1-1.3 3.1-3.1 0-1.8-1.2-3.1-3.1-3.1Z"/></svg>
            ORCID
          </a>
        </div>
      </div>

      <!-- 肖像 -->
      <div class="md:col-span-2 flex justify-center md:justify-end">
        <div class="p-4 rounded-3xl border border-zinc-200 bg-white/70 backdrop-blur">
          <img src="assets/self.jpg" alt="Portrait of Lee Tzu Lam" class="max-w-xs w-auto h-auto rounded-2xl object-contain"/>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Research Areas（保持不变略） -->
<section id="research" class="section">
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-16">
    <div class="section-hd mb-3"><span class="kicker">Section 01</span><div class="rule"></div></div>
    <h2 class="h2">Research Areas</h2>
    <p class="mt-2 muted">Core themes driving my current projects.</p>
    <div class="mt-8 grid sm:grid-cols-2 lg:grid-cols-3 gap-6">
      <article class="rounded-2xl border border-zinc-200 p-5 bg-white"><h3 class="font-semibold">Affective Computing</h3><p class="mt-2 text-sm text-zinc-600">Multimodal emotion recognition and controllable, VAD-consistent generation; reliability testing under polarity flips.</p></article>
      <article class="rounded-2xl border border-zinc-200 p-5 bg-white"><h3 class="font-semibold">Brain-Inspired Cognitive Decision-Making</h3><p class="mt-2 text-sm text-zinc-600">Neuro-symbolic priors, appraisal mechanisms, and self-elicited knowledge distillation to shape reasoning in LMs.</p></article>
      <article class="rounded-2xl border border-zinc-200 p-5 bg-white"><h3 class="font-semibold">Human-Computer Interaction</h3><p class="mt-2 text-sm text-zinc-600">Emotion-centric dialogue systems, trustworthy interaction, and assistive tools for research reproducibility.</p></article>
    </div>
  </div>
</section>

<!-- Future Research：流线科技感拓扑（修复遮挡） -->
<section id="highlights" class="section">
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-16">
    <div class="section-hd mb-3"><span class="kicker">Section 02</span><div class="rule"></div></div>
    <h2 class="h2">Future Research Directions</h2>

    <div class="mt-8 grid md:grid-cols-2 gap-8">
      <div class="space-y-4 text-[.97rem] leading-7 text-zinc-700">
        <p>My near-term agenda focuses on <b>sparse, energy-aware perception</b>, <b>bounded yet reliable decision-making</b>, and <b>explainable human–AI collaboration</b>. Nodes summarize concrete tracks; hover for details. Edges show synergy.</p>
        <div class="rounded-2xl border border-zinc-200 p-4 bg-white text-sm text-zinc-700">
          <b>Research note ·</b> Limiting an <i>amygdala-like</i> mechanism to a <b>single-turn, discrete</b> gate curbs perseveration and affective “echo chambers”. It acts as a <b>bias-control prior</b> that prioritizes salient events without sustaining rumination. Neither induces nor prevents “AI self-awareness”: that would require <b>long-term episodic memory</b>, <b>self-models</b>, and a <b>global workspace</b>. Combine with <b>reset policies</b>, <b>bounded working memory</b>, and <b>audit traces</b>.
        </div>
      </div>

      <div id="future-card">
        <canvas id="futureCanvas"></canvas>
        <div id="future-tip"></div>
      </div>
    </div>
  </div>
</section>

<!-- Publications -->
<section id="publications" class="section">
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-16">
    <div class="section-hd mb-3"><span class="kicker">Section 03</span><div class="rule"></div></div>
    <h2 class="h2">Selected Publications</h2>

    <!-- NeuroGaze-Distill -->
    <div class="mt-8 grid md:grid-cols-2 gap-6 items-start">
      <div class="rounded-2xl border border-zinc-200 p-6 bg-white">
        <h3 class="font-serif text-2xl leading-snug" style="font-family:'EB Garamond',serif">
          <span style="font-variant: small-caps;">NeuroGaze–Distill: Brain-informed Distillation and Depression–Inspired Geometric Priors for Robust Facial Emotion Recognition</span>
        </h3>
        <p class="mt-2 text-sm text-zinc-600"><b>Zilin Li</b>, Weiwei Xu, Xuanqi Zhao, Yiran Zhu · <b>originally planned for ICLR 2026</b></p>
        <p class="mt-3 text-sm text-zinc-700">Cross-modal distillation that transfers neuro-informed priors into an image-only FER student via static V/A prototypes and a depression-inspired geometric prior. Student models trained on FERPlus/AffectNet-mini require no EEG/gaze at deployment.</p>
        <div class="mt-3 text-sm"><a class="underline" href="https://arxiv.org/abs/2509.11916" target="_blank" rel="noopener">arXiv:2509.11916</a></div>
      </div>
      <div class="paper p-3"><img src="assets/N.png" alt="NeuroGaze-Distill graphic" class="w-full h-[360px] rounded-xl border border-zinc-200 object-contain"/></div>
    </div>

    <!-- Flattened No More -->
    <div class="mt-8 grid md:grid-cols-2 gap-6 items-start">
      <div class="rounded-2xl border border-zinc-200 p-6 bg-white">
        <h3 class="font-serif text-2xl leading-snug" style="font-family:'EB Garamond',serif">
          <span style="font-variant: small-caps;">Flattened No More: Teaching VLMs to Think Stepwise via Self-Elicited Knowledge Distillation</span>
        </h3>
        <p class="mt-2 text-sm text-zinc-600">Wei Yang, Yiran Zhu, <b>Zilin Li</b>, Xunjia Zhang, Hongtao Wang · <b>targeting CVPR 2026</b></p>
        <p class="mt-3 text-sm text-zinc-700">We elicit and distill self-generated intermediate rationales from VLMs to encourage stepwise reasoning. The method improves chain-of-thought faithfulness while keeping decoding simple and reproducible.</p>
      </div>
      <div class="paper p-3"><img src="assets/F.png" alt="Flattened No More graphic" class="w-full h-[360px] rounded-xl border border-zinc-200 object-contain"/></div>
    </div>

    <!-- EmoLoom-2B -->
    <div class="mt-8 grid md:grid-cols-2 gap-6 items-start">
      <div class="rounded-2xl border border-zinc-200 p-6 bg-white">
        <h3 class="font-serif text-2xl leading-snug" style="font-family:'EB Garamond',serif">
          <span style="font-variant: small-caps;">EmoLoom–2B: Emotion-centric QA/VAD Large Language Model</span>
        </h3>
        <p class="mt-2 text-sm text-zinc-600"><b>Zilin Li*</b>, Weiwei Xu*, Yiran Zhu, Yuxiu Zhang · arXiv planned in <b>2026</b></p>
        <p class="mt-3 text-sm text-zinc-700">A ~2B-parameter LLM tailored for emotion-centric QA with VAD-preserving objectives and an appraisal verifier. Stress-tests show steadier valence under polarity flips and fewer format failures.</p>
      </div>
      <div class="paper p-3"><img src="assets/E.png" alt="EmoLoom-2B graphic" class="w-full h-[360px] rounded-xl border border-zinc-200 object-contain"/></div>
    </div>
  </div>
</section>

<!-- Experience（保持你上次的增强版） -->
<section id="experience" class="section">
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-16">
    <div class="section-hd mb-3"><span class="kicker">Section 04</span><div class="rule"></div></div>
    <h2 class="h2">Research & Leadership Experience</h2>
    <div class="mt-8 timeline">
      <div class="t-item">
        <div class="t-dot"></div>
        <div class="t-hd">
          <div>
            <div class="t-role">Founder, ACHCI Lab <span class="muted">(Affective Computing & Human-Computer Interaction Laboratory)</span></div>
            <div class="t-where">Independent Research Group</div>
          </div>
          <div class="t-when">2025 – Present</div>
        </div>
        <div class="t-body">
          Lead end-to-end projects with <b>full pipeline ownership</b>: problem framing → dataset curation/cleansing → modular codebase & training stack → benchmark suites with deterministic seeds → <b>cross-dataset ablations</b> & stress-tests → writing and camera-ready polishing. Emphasize <b>reproducibility</b>, <b>open science</b>, and robust HCI.
          <div class="mt-2"><span class="pill">reproducibility</span><span class="pill">affective-AI</span><span class="pill">multimodal</span><span class="pill">open-science</span></div>
        </div>
      </div>
      <div class="t-item">
        <div class="t-dot"></div>
        <div class="t-hd">
          <div>
            <div class="t-role">Research Engineer & Collaborator</div>
            <div class="t-where">Open-source & academic collaborations</div>
          </div>
          <div class="t-when">2024 – Present</div>
        </div>
        <div class="t-body">
          Built publication-grade training (AMP, channels-last, gradient-checkpointing), efficient dataloaders, and <b>benchmark harnesses</b> with offline caches/seed control. Comfortable with dataset design, experiment tracking, ablation strategy, and <b>paper-ready figures/tables</b>. Known for practical debugging and fast iteration.
          <div class="mt-2"><span class="pill">benchmarks</span><span class="pill">cross-dataset</span><span class="pill">MNE-Python</span><span class="pill">AMP</span><span class="pill">grad-checkpoint</span></div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Education（含 Chiba） -->
<section id="education" class="section">
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-16">
    <div class="section-hd mb-3"><span class="kicker">Section 05</span><div class="rule"></div></div>
    <h2 class="h2">Education</h2>

    <div class="mt-8 timeline">
      <div class="t-item">
        <div class="t-dot"></div>
        <div class="t-hd">
          <div class="flex items-start gap-3">
            <div class="crest-wrap"><img src="assets/sjtunew.png" alt="SJTU crest" class="crest" loading="lazy"/></div>
            <div>
              <div class="t-role">Intern</div>
              <div class="t-where">Shanghai Jiao Tong University · Shanghai <a class="underline" href="https://www.sjtu.edu.cn" target="_blank" rel="noopener">(sjtu.edu.cn)</a></div>
            </div>
          </div>
          <div class="t-when">2025 – Present</div>
        </div>
      </div>

      <div class="t-item">
        <div class="t-dot"></div>
        <div class="t-hd">
          <div class="flex items-start gap-3">
            <div class="crest-wrap"><img src="assets/dhunew.png" alt="DHU crest" class="crest" loading="lazy"/></div>
            <div>
              <div class="t-role">Undergrad Student</div>
              <div class="t-where">School of Computer Science & Technology, Donghua University · Shanghai <a class="underline" href="https://mail.dhu.edu.cn" target="_blank" rel="noopener">(mail.dhu.edu.cn)</a></div>
            </div>
          </div>
          <div class="t-when">2023 – Present</div>
        </div>
      </div>

      <div class="t-item">
        <div class="t-dot"></div>
        <div class="t-hd">
          <div class="flex items-start gap-3">
            <div class="crest-wrap"><img src="assets/chiba.svg" alt="Chiba University crest" class="crest" loading="lazy"/></div>
            <div>
              <div class="t-role">Visiting Student</div>
              <div class="t-where">Chiba University · Japan</div>
            </div>
          </div>
          <div class="t-when">2025</div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Contact -->
<section id="contact" class="section">
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-16">
    <div class="section-hd mb-3"><span class="kicker">Section 06</span><div class="rule"></div></div>
    <h2 class="h2">Contact</h2>
    <div class="mt-8 rounded-2xl border border-zinc-200 p-6 bg-white">
      <div class="text-sm muted">Email</div>
      <a class="mt-1 inline-flex items-center gap-2 text-lg font-semibold underline" href="mailto:tzulamlee@gmail.com">
        <svg width="18" height="18" viewBox="0 0 256 262" xmlns="http://www.w3.org/2000/svg"><path fill="#4285F4" d="M255.9 133.5c0-10.3-.8-17.8-2.5-25.6H130v46.5h72.5c-1.5 11.6-9.6 29-27.6 40.7l-.3 2.1 40.1 31 2.8.3c25.6-23.6 40.4-58.3 40.4-95z"/><path fill="#34A853" d="M130.1 261.1c36.7 0 67.4-12.1 89.8-33l-42.8-33.1c-11.5 8-26.9 13.6-47 13.6-35.9 0-66.4-23.6-77.2-56.3l-2 .2-41.9 32.4-.5 1.9c22.2 44.1 67.7 74.3 121.6 74.3z"/><path fill="#FBBC05" d="M52.8 152.2c-2.9-8.7-4.6-18-4.6-27.5s1.7-18.8 4.6-27.5l-.1-1.9L10.4 62.3l-1.8.8C2.9 78.3 0 95.4 0 113.7s2.9 35.4 8.6 50.6l44.2-12.1z"/><path fill="#EA4335" d="M130.1 50.9c25.5 0 42.6 11 52.4 20.2l38.2-37.2C197.3 12.1 166.7 0 130.1 0 76.2 0 30.7 30.2 8.5 74.4l44.3 34.9c10.8-32.7 41.3-58.4 77.3-58.4z"/></svg>
        tzulamlee@gmail.com
      </a>
      <p class="mt-2 text-sm lead">For collaboration on affective computing, brain-inspired decision-making, and HCI.</p>
    </div>
    <p class="mt-10 text-xs muted">© <span id="year"></span> ACHCI Lab · Lee Tzu Lam. All rights reserved.</p>
  </div>
</section>

<script>
/* 年份 */
document.getElementById('year').textContent = new Date().getFullYear();

/* 顶部粒子背景（保持） */
const canvas=document.getElementById('particles'),ctx=canvas.getContext('2d');
let W,H,DPR=Math.min(window.devicePixelRatio||1,2);const N=80,parts=[];
function resize(){W=canvas.clientWidth=canvas.offsetWidth;H=canvas.clientHeight=canvas.offsetHeight;canvas.width=W*DPR;canvas.height=H*DPR;ctx.setTransform(DPR,0,0,DPR,0,0)}
window.addEventListener('resize',resize,{passive:true});resize();
function r(a,b){return a+Math.random()*(b-a)}
for(let i=0;i<N;i++)parts.push({x:r(0,W),y:r(0,H*.9),vx:r(-.2,.2),vy:r(-.1,.1),r:r(1,2.4),a:r(.2,.8)});
(function step(){ctx.clearRect(0,0,W,H);for(const p of parts){p.x+=p.vx;p.y+=p.vy;if(p.x<0||p.x>W)p.vx*=-1;if(p.y<0||p.y>H)p.vy*=-1;ctx.beginPath();ctx.arc(p.x,p.y,p.r,0,Math.PI*2);ctx.fillStyle=`rgba(80,80,120,${p.a})`;ctx.fill()}
for(let i=0;i<parts.length;i++)for(let j=i+1;j<parts.length;j++){const a=parts[i],b=parts[j],d=Math.hypot(a.x-b.x,a.y-b.y);if(d<90){ctx.strokeStyle='rgba(60,60,120,.06)';ctx.lineWidth=1;ctx.beginPath();ctx.moveTo(a.x,a.y);ctx.lineTo(b.x,b.y);ctx.stroke()}}requestAnimationFrame(step)})();

/* Future Map — 发光流线力导向 */
const wrap=document.getElementById('future-card');
const tip=document.getElementById('future-tip');
const fcv=document.getElementById('futureCanvas'),fctx=fcv.getContext('2d');
function fResize(){const rct=wrap.getBoundingClientRect();fcv.width=rct.width*DPR;fcv.height=rct.height*DPR;fcv.style.width=rct.width+'px';fcv.style.height=rct.height+'px';fctx.setTransform(DPR,0,0,DPR,0,0)}
window.addEventListener('resize',fResize,{passive:true});fResize();

/* 节点与描述 */
const nodes=[
  {id:0, label:'Sparse Activation', desc:'Cortical-like routing/gating (top-k, Hebbian-style) for efficient affect perception.'},
  {id:1, label:'Efficient Decision', desc:'Amortized tree search + model-based RL under cognitive bounds for safe HCI.'},
  {id:2, label:'Ling-MCP', desc:'Memory-constrained planning with rolling summaries & resets.'},
  {id:3, label:'Ling-CoT', desc:'Evolutionary mutations/selection to harden CoT to polarity/prompt shifts.'},
  {id:4, label:'HCI · evo-loops', desc:'Interactive tutoring/co-creation that adapts feedback to user affect.'},
  {id:5, label:'Agents', desc:'Tool-use with self-reflection checkpoints and affect cues.'},
  {id:6, label:'Layer Probing', desc:'Representation surgery + causal mediation to localize appraisal/valence.'},
  {id:7, label:'ChineseEEG-2', desc:'Bilingual speech↔listening dataset; standardized MNE-Python pipeline.'},
  {id:8, label:'NCC Pipelines', desc:'EEG/MEG pipelines, deterministic eval, stress-tests.'},
  {id:9, label:'Seed-V / OCR', desc:'VL preprocessing & document understanding for affect QA.'},
  {id:10,label:'Amygdala-gate', desc:'Single-turn discrete gate to prioritize salience without rumination.'},
];
const edges=[[0,1],[0,2],[2,3],[1,4],[4,5],[5,6],[4,8],[7,8],[8,9],[5,10],[0,6],[6,2],[3,6],[1,10]];

/* 初始分布尽量填满画布可视区 */
function Wm(){return fcv.width/DPR} function Hm(){return fcv.height/DPR}
nodes.forEach(n=>{n.x=r(Wm()*0.18,Wm()*0.85);n.y=r(Hm()*0.18,Hm()*0.82);n.vx=0;n.vy=0});
let hover=null;const A='#60a5fa',B='#a78bfa';
function tick(){
  const k=0.04, rep=1300, damp=.86;
  for(let i=0;i<nodes.length;i++)for(let j=i+1;j<nodes.length;j++){
    const a=nodes[i],b=nodes[j];let dx=a.x-b.x,dy=a.y-b.y,d=Math.hypot(dx,dy)+.01;
    const F=rep/(d*d);dx/=d;dy/=d;a.vx+=dx*F;a.vy+=dy*F;b.vx-=dx*F;b.vy-=dy*F
  }
  for(const [i,j] of edges){
    const a=nodes[i],b=nodes[j];let dx=b.x-a.x,dy=b.y-a.y,d=Math.hypot(dx,dy)+.01;
    const L=118,F=k*(d-L);dx/=d;dy/=d;a.vx+=dx*F;a.vy+=dy*F;b.vx-=dx*F;b.vy-=dy*F
  }
  for(const n of nodes){
    n.vx*=damp;n.vy*=damp;n.x+=n.vx;n.y+=n.vy;
    const pad=28;if(n.x<pad||n.x>Wm()-pad)n.vx*=-1;if(n.y<pad||n.y>Hm()-pad)n.vy*=-1
  }
}
function draw(){
  fctx.clearRect(0,0,Wm(),Hm());tick();
  const t=Date.now()/1000;
  // 渐变连线 + 脉动
  for(const [i,j] of edges){
    const a=nodes[i],b=nodes[j];
    const g=fctx.createLinearGradient(a.x,a.y,b.x,b.y);g.addColorStop(0,A);g.addColorStop(1,B);
    fctx.strokeStyle=`rgba(99,102,241,${0.32+0.14*Math.sin(t+i)})`;fctx.lineWidth=1.25;
    fctx.shadowColor='rgba(99,102,241,.35)';fctx.shadowBlur=4;
    fctx.beginPath();fctx.moveTo(a.x,a.y);fctx.lineTo(b.x,b.y);fctx.stroke();
  }
  fctx.shadowBlur=0;
  // 节点发光
  for(const n of nodes){
    const glow=fctx.createRadialGradient(n.x,n.y,0,n.x,n.y,18);glow.addColorStop(0,'rgba(99,102,241,.35)');glow.addColorStop(1,'rgba(99,102,241,0)');
    fctx.fillStyle=glow;fctx.beginPath();fctx.arc(n.x,n.y,18,0,Math.PI*2);fctx.fill();
    const fill=fctx.createLinearGradient(n.x-10,n.y-10,n.x+10,n.y+10);fill.addColorStop(0,A);fill.addColorStop(1,B);
    fctx.fillStyle=fill;fctx.beginPath();fctx.arc(n.x,n.y,(hover===n?7:5.2),0,Math.PI*2);fctx.fill();
    fctx.font='600 12.5px Inter, ui-sans-serif';fctx.fillStyle='#1f2937';fctx.textAlign='center';fctx.fillText(n.label,n.x,n.y-14);
  }
  requestAnimationFrame(draw)
}
draw();

/* hover hit test + tooltip 防越界 */
function hit(x,y){for(const n of nodes){if(Math.hypot(x-n.x,y-n.y)<=10)return n}return null}
fcv.addEventListener('mousemove',e=>{
  const rect=fcv.getBoundingClientRect();const x=(e.clientX-rect.left),y=(e.clientY-rect.top);
  hover=hit(x,y);
  if(hover){tip.style.display='block';tip.textContent=hover.desc;
    const tw=tip.offsetWidth,th=tip.offsetHeight;let tx=x+16,ty=y+16;
    if(tx+tw>rect.width)tx=x-tw-16;if(ty+th>rect.height)ty=y-th-16;tip.style.transform=`translate(${tx}px,${ty}px)`;
  }else tip.style.display='none';
});
</script>
</body>
</html>
