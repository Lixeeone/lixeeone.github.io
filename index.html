<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>Lee Tzu Lam — ACHCI Lab</title>
<meta name="description" content="Lee Tzu Lam — Founder of ACHCI Lab. Research in Affective Computing, Brain-Inspired Cognitive Decision-Making, and HCI."/>
<meta property="og:title" content="Lee Tzu Lam — ACHCI Lab"/>
<meta property="og:description" content="Founder of ACHCI Lab. Affective Computing · Brain-Inspired Cognition · HCI"/>
<meta property="og:type" content="website"/>
<meta property="og:url" content="https://lixeeone.github.io"/>
<meta property="og:image" content="assets/self.jpg"/>
<link rel="icon" href="assets/logo.png"/>
<script src="https://cdn.tailwindcss.com"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=EB+Garamond:wght@500;700&family=Literata:opsz,wght@7..72,500;7..72,600&display=swap" rel="stylesheet">
<style>
  html{scroll-behavior:smooth}
  body{background:#fff;color:#161616;font-family:Inter,ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,"Helvetica Neue",Arial}
  .glass{background:rgba(255,255,255,.7);backdrop-filter:blur(8px)}
  .section{border-top:1px solid #e9e9e9}
  .latex-title{font-family:"EB Garamond",ui-serif,Georgia,"Times New Roman",serif;letter-spacing:.02em}
  .latex-smcaps{font-variant:small-caps}
  .brand-gradient{background:linear-gradient(90deg,#0ea5e9,#6366f1,#ec4899);-webkit-background-clip:text;background-clip:text;color:transparent}
  .kicker{letter-spacing:.18em;text-transform:uppercase;font-size:.72rem;color:#6b7280}
  .section-hd{display:flex;align-items:center;gap:.9rem}
  .section-hd .rule{height:1px;flex:1;background:linear-gradient(90deg,#e5e7eb,transparent)}
  .h2{font-size:1.5rem;font-weight:700;letter-spacing:.2px}
  .muted{color:#6b7280}
  .lead{color:#4b5563;line-height:1.7}

  /* ===== HERO 背景 ===== */
  .moving-gradient::before{
    content:"";position:absolute;inset:0;z-index:0;opacity:.6;
    background:
      radial-gradient(60% 50% at 50% 10%,rgba(99,102,241,.18),transparent 60%),
      radial-gradient(40% 30% at 80% 0%,rgba(14,165,233,.16),transparent 60%),
      radial-gradient(30% 25% at 20% 0%,rgba(236,72,153,.14),transparent 60%);
    animation:floatGrad 18s ease-in-out infinite alternate;pointer-events:none;
  }
  @keyframes floatGrad{0%{transform:translateY(-3%) scale(1)}100%{transform:translateY(3%) scale(1.05)}}
  #particles{position:absolute;inset:0;z-index:1;pointer-events:none;opacity:.55}
  .hero-inner{position:relative;z-index:2}

  /* ===== 研究宣言（静态起伏） ===== */
  .rq{position:relative;margin-top:18px}
  .rq::before,.rq::after{
    position:absolute;font-family:"EB Garamond",ui-serif,Georgia,"Times New Roman",serif;
    color:#94a3b8;opacity:.12;line-height:.9;pointer-events:none
  }
  .rq::before{content:"“";font-size:58px;left:-10px;top:-10px}
  .rq::after {content:"”";font-size:50px;right:-10px;bottom:-14px}
  .rq-static{
    font-family:"Literata",ui-serif,Georgia,"Times New Roman",serif;
    font-size:1.05rem; line-height:1.9;
    word-spacing:.14em; letter-spacing:.02em; color:#374151;
  }
  .rq-static .w{display:inline-block}

  /* ===== 右侧竖排水印 ===== */
  .wm-fixed{
    position:fixed;right:10px;top:50%;transform:translateY(-50%);
    writing-mode:vertical-rl;text-orientation:mixed;
    font-family:"EB Garamond",ui-serif,Georgia,"Times New Roman",serif;
    font-weight:700;font-size:clamp(18px,2.2vw,24px);
    background:linear-gradient(180deg,#0ea5e9,#6366f1,#ec4899);
    -webkit-background-clip:text;background-clip:text;color:transparent;
    opacity:.07;user-select:none;pointer-events:none;z-index:50;
  }

  /* ===== 通用卡片 / 时间线 ===== */
  .spec{background:#fff;border:1px solid #e7e7ea;border-radius:16px;padding:22px 22px 20px 26px;position:relative}
  .spec::before{content:"";position:absolute;left:-1px;top:-1px;bottom:-1px;width:4px;background:linear-gradient(180deg,#93c5fd,#a5b4fc 60%,#f0abfc);border-radius:16px 0 0 16px}
  .spec h3{font-weight:600;margin-bottom:.35rem}.spec p{font-size:.925rem;color:#52525b}
  .paper{background:#f8f9fb;border:1px solid #e5e7eb;border-radius:12px;transition:box-shadow .25s,transform .25s}
  .paper:hover{box-shadow:0 16px 40px rgba(2,6,23,.08);transform:translateY(-2px)}
  .timeline{position:relative;padding-left:22px}
  .timeline::before{content:"";position:absolute;left:8px;top:6px;bottom:6px;width:2px;background:#e5e7eb}
  .t-item{position:relative;padding:18px;border:1px solid #ececec;border-radius:14px;background:#fff}
  .t-item+.t-item{margin-top:14px}
  .t-dot{position:absolute;left:-22px;top:22px;width:10px;height:10px;border-radius:999px;background:#6366f1;box-shadow:0 0 0 4px #eef2ff}
  .t-hd{display:flex;align-items:flex-start;justify-content:space-between;gap:1rem}
  .t-role{font-weight:600}.t-where{color:#6b7280;font-size:.92rem}.t-when{color:#6b7280;font-size:.9rem;white-space:nowrap}
  .t-body{margin-top:.5rem;color:#4b5563;font-size:.95rem;line-height:1.7}
  .pill{display:inline-block;padding:.25rem .55rem;border:1px solid #e6e6ef;border-radius:999px;font-size:.78rem;color:#555;background:#fbfbfe;margin-right:.35rem}

  /* ===== 校徽容器 ===== */
  .crest-wrap{width:44px;height:44px;display:flex;align-items:center;justify-content:center}
  .crest{max-width:100%;max-height:100%;object-fit:contain}

  /* ===== Future Map 容器 ===== */
  #future-map{position:relative;height:520px;border:1px solid #ececf2;background:linear-gradient(180deg,#fafafa,#fff);border-radius:16px;overflow:hidden}
  #futureCanvas{position:absolute;inset:0}
  #future-tip{position:absolute;max-width:420px;font-size:.86rem;line-height:1.55;background:#ffffffe6;border:1px solid #e6e6ef;padding:.6rem .7rem;border-radius:.75rem;backdrop-filter:blur(6px);box-shadow:0 10px 24px rgba(2,6,23,.08);display:none;pointer-events:none}

  /* ===== Lightbox ===== */
  .lightbox{position:fixed;inset:0;background:rgba(0,0,0,.64);display:none;align-items:center;justify-content:center;z-index:80}
  .lightbox[data-open="true"]{display:flex}
  .lightbox img{max-width:min(96vw,1400px);max-height:92vh;border-radius:1rem;box-shadow:0 30px 80px rgba(0,0,0,.35)}
  .lightbox .close{position:absolute;top:18px;right:22px;color:#fff;font-size:22px;opacity:.9}
</style>
</head>

<body class="antialiased">

<!-- 右侧竖排水印 -->
<div class="wm-fixed">AI4Science, Science2AI</div>

<!-- 顶部导航（Logo 1.5×） -->
<header class="sticky top-0 z-50 border-b border-zinc-200 glass">
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 h-16 flex items-center justify-between">
    <a href="#home" class="flex items-center gap-3">
      <img src="assets/logo.png" alt="ACHCI Lab logo" class="w-20 h-20 -my-2 object-contain"/>
      <span class="font-semibold brand-gradient text-lg">ACHCI Lab</span>
    </a>
    <nav class="hidden md:flex items-center gap-8 text-sm text-zinc-700">
      <a href="#research" class="hover:opacity-80">Research</a>
      <a href="#highlights" class="hover:opacity-80">Future</a>
      <a href="#publications" class="hover:opacity-80">Publications</a>
      <a href="#experience" class="hover:opacity-80">Experience</a>
      <a href="#education" class="hover:opacity-80">Education</a>
      <a href="#contact" class="hover:opacity-80">Contact</a>
    </nav>
  </div>
</header>

<!-- HERO -->
<section id="home" class="relative overflow-hidden moving-gradient">
  <canvas id="particles"></canvas>
  <div class="hero-inner max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-16 sm:py-24 grid md:grid-cols-5 gap-10 items-center">
    <div class="md:col-span-3">
      <p class="kicker">Founder, ACHCI Lab</p>
      <h1 class="mt-2 text-4xl sm:text-5xl font-extrabold leading-tight">Lee Tzu Lam</h1>
      <div class="rq">
        <p id="rqText" class="rq-static">
          My research spans Affective Computing, Brain-Inspired Cognitive Decision-Making, and Human-Computer Interaction. I build reproducible AI systems and multimodal models that understand and respond to human emotion.
        </p>
      </div>
      <div class="mt-6 flex flex-wrap gap-3">
        <a href="https://github.com/Lixeeone" target="_blank" class="inline-flex items-center gap-2 border border-zinc-300 px-4 py-2 rounded-2xl text-sm hover:bg-zinc-50">GitHub</a>
        <a href="https://huggingface.co/Lixeeone" target="_blank" class="inline-flex items-center gap-2 border border-zinc-300 px-4 py-2 rounded-2xl text-sm hover:bg-zinc-50">Hugging Face</a>
        <a href="https://orcid.org/0009-0002-4314-455X" target="_blank" class="inline-flex items-center gap-2 border border-zinc-300 px-4 py-2 rounded-2xl text-sm hover:bg-zinc-50">ORCID</a>
      </div>
    </div>
    <div class="md:col-span-2 flex justify-center md:justify-end">
      <div class="p-4 rounded-3xl border border-zinc-200 bg-white/70 backdrop-blur">
        <img src="assets/self.jpg" alt="Lee Tzu Lam" class="max-w-xs rounded-2xl object-contain"/>
      </div>
    </div>
  </div>
</section>

<!-- Research Areas -->
<section id="research" class="section">
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-16">
    <div class="section-hd mb-3"><span class="kicker">Section 01</span><div class="rule"></div></div>
    <h2 class="h2">Research Areas</h2>
    <p class="mt-2 muted">Core themes driving my current projects.</p>
    <div class="mt-8 grid sm:grid-cols-2 lg:grid-cols-3 gap-6">
      <article class="spec"><h3>Affective Computing</h3><p>Multimodal emotion recognition and controllable, VAD-consistent generation; reliability testing under polarity flips.</p></article>
      <article class="spec"><h3>Brain-Inspired Cognitive Decision-Making</h3><p>Neuro-symbolic priors, appraisal mechanisms, and self-elicited knowledge distillation to shape reasoning in LMs.</p></article>
      <article class="spec"><h3>Human-Computer Interaction</h3><p>Emotion-centric dialogue systems, trustworthy interaction, and assistive tools for research reproducibility.</p></article>
    </div>
  </div>
</section>

<!-- Future: 高级拓扑图 -->
<section id="highlights" class="section">
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-16">
    <div class="section-hd mb-3"><span class="kicker">Section 02</span><div class="rule"></div></div>
    <h2 class="h2">Future Research Directions</h2>

    <div class="mt-8 grid md:grid-cols-2 gap-8">
      <div class="space-y-4 text-[.97rem] leading-7 text-zinc-700">
        <p>My near-term agenda focuses on <b>sparse, energy-aware perception</b>, <b>bounded yet reliable decision-making</b>, and <b>explainable human–AI collaboration</b>. Nodes summarize concrete tracks; hover for details. Edges show synergy.</p>
        <div class="rounded-2xl border border-zinc-200 p-4 bg-white text-sm text-zinc-700">
          <b>Research note ·</b> Limiting an <i>amygdala-like</i> mechanism to a <b>single-turn, discrete</b> gate curbs perseveration and affective “echo chambers”. It acts as a <b>bias-control prior</b> that prioritizes salient events without sustaining rumination. Neither induces nor prevents “AI self-awareness”: that would require <b>long-term episodic memory</b>, <b>self-models</b>, and a <b>global workspace</b>. Combine with <b>reset policies</b>, <b>bounded working memory</b>, and <b>audit traces</b> for safety.
        </div>
      </div>

      <div id="future-map">
        <canvas id="futureCanvas"></canvas>
        <div id="future-tip"></div>
      </div>
    </div>
  </div>
</section>

<!-- Publications -->
<section id="publications" class="section">
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-16">
    <div class="section-hd mb-3"><span class="kicker">Section 03</span><div class="rule"></div></div>
    <h2 class="h2">Selected Publications</h2>

    <!-- NeuroGaze-Distill -->
    <div class="mt-8 grid md:grid-cols-2 gap-6 items-start">
      <div class="rounded-2xl border border-zinc-200 p-6 bg-white">
        <h3 class="latex-title text-2xl leading-snug">
          <span class="latex-smcaps">NeuroGaze–Distill: Brain-informed Distillation and Depression–Inspired Geometric Priors for Robust Facial Emotion Recognition</span>
        </h3>
        <p class="mt-2 text-sm muted"><b>Zilin Li</b>, Weiwei Xu, Xuanqi Zhao, Yiran Zhu · <i>Originally planned for ICLR 2026</i></p>
        <p class="mt-3 text-sm lead">
          Cross-modal distillation that transfers neuro-informed priors into an image-only FER student via static V/A prototypes and a depression-inspired geometric prior. Student models trained on FERPlus/AffectNet-mini require no EEG/gaze at deployment.
        </p>
        <div class="mt-3 text-sm"><a class="underline" href="https://arxiv.org/abs/2509.11916" target="_blank" rel="noopener">arXiv:2509.11916</a></div>
      </div>
      <div class="paper p-3">
        <img src="assets/N.png" alt="NeuroGaze-Distill graphic" class="w-full h-[360px] rounded-xl border border-zinc-200 object-contain cursor-zoom-in" data-lightbox="assets/N.png"/>
      </div>
    </div>

    <!-- Flattened No More -->
    <div class="mt-8 grid md:grid-cols-2 gap-6 items-start">
      <div class="rounded-2xl border border-zinc-200 p-6 bg-white">
        <h3 class="latex-title text-2xl leading-snug">
          <span class="latex-smcaps">Flattened No More: Teaching VLMs to Think Stepwise via Self-Elicited Knowledge Distillation</span>
        </h3>
        <p class="mt-2 text-sm muted">Wei Yang, Yiran Zhu, <b>Zilin Li</b>, Xunjia Zhang, Hongtao Wang · <b>Targeting CVPR 2026</b></p>
        <p class="mt-3 text-sm lead">
          We elicit and distill self-generated intermediate rationales from VLMs to encourage stepwise reasoning. The method improves chain-of-thought faithfulness while keeping decoding simple and reproducible.
        </p>
      </div>
      <div class="paper p-3">
        <img src="assets/F.png" alt="Flattened No More graphic" class="w-full h-[360px] rounded-xl border border-zinc-200 object-contain cursor-zoom-in" data-lightbox="assets/F.png"/>
      </div>
    </div>

    <!-- EmoLoom-2B -->
    <div class="mt-8 grid md:grid-cols-2 gap-6 items-start">
      <div class="rounded-2xl border border-zinc-200 p-6 bg-white">
        <h3 class="latex-title text-2xl leading-snug">
          <span class="latex-smcaps">EmoLoom–2B: Emotion-centric QA/VAD Large Language Model</span>
        </h3>
        <p class="mt-2 text-sm muted"><b>Zilin Li*</b>, Weiwei Xu*, Yiran Zhu, Yuxiu Zhang · arXiv planned in <b>2026</b></p>
        <p class="mt-3 text-sm lead">
          A ~2B-parameter LLM tailored for emotion-centric QA with VAD-preserving objectives and an appraisal verifier. Stress-tests show steadier valence under polarity flips and fewer format failures.
        </p>
      </div>
      <div class="paper p-3">
        <img src="assets/E.png" alt="EmoLoom-2B graphic" class="w-full h-[360px] rounded-xl border border-zinc-200 object-contain cursor-zoom-in" data-lightbox="assets/E.png"/>
      </div>
    </div>
  </div>
</section>

<!-- Experience -->
<section id="experience" class="section">
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-16">
    <div class="section-hd mb-3"><span class="kicker">Section 04</span><div class="rule"></div></div>
    <h2 class="h2">Research & Leadership Experience</h2>
    <div class="mt-8 timeline">
      <div class="t-item">
        <div class="t-dot"></div>
        <div class="t-hd">
          <div>
            <div class="t-role">Founder, ACHCI Lab <span class="muted">(Affective Computing & Human-Computer Interaction Laboratory)</span></div>
            <div class="t-where">Independent Research Group</div>
          </div>
          <div class="t-when">2025 – Present</div>
        </div>
        <div class="t-body">
          Lead end-to-end projects with <b>full pipeline ownership</b>: problem framing → dataset curation/cleansing → modular codebase & training stack → benchmark suites with deterministic seeds → <b>cross-dataset ablations</b> & stress-tests → writing and camera-ready polishing. Emphasize <b>reproducibility</b>, <b>open science</b>, and robust HCI.
          <div class="mt-2"><span class="pill">reproducibility</span><span class="pill">affective-AI</span><span class="pill">multimodal</span><span class="pill">open-science</span></div>
        </div>
      </div>
      <div class="t-item">
        <div class="t-dot"></div>
        <div class="t-hd">
          <div>
            <div class="t-role">Research Engineer & Collaborator</div>
            <div class="t-where">Open-source & academic collaborations</div>
          </div>
          <div class="t-when">2024 – Present</div>
        </div>
        <div class="t-body">
          Built publication-grade training (AMP, channels-last, gradient-checkpointing), efficient dataloaders, and <b>benchmark harnesses</b> with offline caches/seed control. Comfortable with dataset design, experiment tracking, ablation strategy, and <b>paper-ready figures/tables</b>. Known for practical debugging and fast iteration.
          <div class="mt-2"><span class="pill">benchmarks</span><span class="pill">cross-dataset</span><span class="pill">MNE-Python</span><span class="pill">AMP</span><span class="pill">grad-checkpoint</span></div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Education -->
<section id="education" class="section">
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-16">
    <div class="section-hd mb-3"><span class="kicker">Section 05</span><div class="rule"></div></div>
    <h2 class="h2">Education</h2>
    <div class="mt-8 timeline">
      <div class="t-item">
        <div class="t-dot"></div>
        <div class="t-hd">
          <div class="flex items-start gap-3">
            <div class="crest-wrap"><img src="assets/sjtunew.png" class="crest" alt="SJTU"/></div>
            <div><div class="t-role">Intern</div><div class="t-where">Shanghai Jiao Tong University · Shanghai <a href="https://www.sjtu.edu.cn" target="_blank" class="underline">(sjtu.edu.cn)</a></div></div>
          </div>
          <div class="t-when">2025 – Present</div>
        </div>
      </div>
      <div class="t-item">
        <div class="t-dot"></div>
        <div class="t-hd">
          <div class="flex items-start gap-3">
            <div class="crest-wrap"><img src="assets/dhunew.png" class="crest" alt="DHU"/></div>
            <div><div class="t-role">Undergrad Student</div><div class="t-where">School of Computer Science & Technology, Donghua University · Shanghai <a href="https://mail.dhu.edu.cn" target="_blank" class="underline">(mail.dhu.edu.cn)</a></div></div>
          </div>
          <div class="t-when">2023 – Present</div>
        </div>
      </div>
      <div class="t-item">
        <div class="t-dot"></div>
        <div class="t-hd">
          <div class="flex items-start gap-3">
            <div class="crest-wrap"><img src="assets/chiba.svg" class="crest" alt="Chiba University"/></div>
            <div><div class="t-role">Visiting Student</div><div class="t-where">Chiba University · Japan <a href="https://www.chiba-u.ac.jp/e/" target="_blank" class="underline">(chiba-u.ac.jp)</a></div></div>
          </div>
          <div class="t-when">2025</div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Contact -->
<section id="contact" class="section">
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-16">
    <div class="section-hd mb-3"><span class="kicker">Section 06</span><div class="rule"></div></div>
    <h2 class="h2">Contact</h2>
    <div class="mt-8 rounded-2xl border border-zinc-200 p-6 bg-white">
      <div class="text-sm muted">Email</div>
      <a class="mt-1 inline-flex items-center gap-2 text-lg font-semibold underline" href="mailto:tzulamlee@gmail.com">
        <!-- Google 风格彩色图标 -->
        <svg width="18" height="18" viewBox="0 0 256 262" xmlns="http://www.w3.org/2000/svg"><path fill="#4285F4" d="M255.9 133.5c0-10.3-.8-17.8-2.5-25.6H130v46.5h72.5c-1.5 11.6-9.6 29-27.6 40.7l-.3 2.1 40.1 31 2.8.3c25.6-23.6 40.4-58.3 40.4-95z"/><path fill="#34A853" d="M130.1 261.1c36.7 0 67.4-12.1 89.8-33l-42.8-33.1c-11.5 8-26.9 13.6-47 13.6-35.9 0-66.4-23.6-77.2-56.3l-2 .2-41.9 32.4-.5 1.9c22.2 44.1 67.7 74.3 121.6 74.3z"/><path fill="#FBBC05" d="M52.8 152.2c-2.9-8.7-4.6-18-4.6-27.5s1.7-18.8 4.6-27.5l-.1-1.9L10.4 62.3l-1.8.8C2.9 78.3 0 95.4 0 113.7s2.9 35.4 8.6 50.6l44.2-12.1z"/><path fill="#EA4335" d="M130.1 50.9c25.5 0 42.6 11 52.4 20.2l38.2-37.2C197.3 12.1 166.7 0 130.1 0 76.2 0 30.7 30.2 8.5 74.4l44.3 34.9c10.8-32.7 41.3-58.4 77.3-58.4z"/></svg>
        tzulamlee@gmail.com
      </a>
      <p class="mt-2 text-sm lead">For collaboration on affective computing, brain-inspired decision-making, and HCI.</p>
    </div>
    <p class="mt-10 text-xs muted">© <span id="year"></span> ACHCI Lab · Lee Tzu Lam. All rights reserved.</p>
  </div>
</section>

<!-- Lightbox -->
<div id="lb" class="lightbox" role="dialog" aria-modal="true" aria-label="Image preview">
  <span class="close">✕</span><img id="lb-img" alt="preview"/>
</div>

<script>
/* 年份 */
const y=document.getElementById('year'); if(y) y.textContent=new Date().getFullYear();

/* HERO 粒子 */
(function(){
  const cvs=document.getElementById('particles'); if(!cvs) return;
  const ctx=cvs.getContext('2d'); let W,H,DPR=Math.min(window.devicePixelRatio||1,2);
  const N=80,parts=[]; function resize(){W=cvs.clientWidth=cvs.offsetWidth;H=cvs.clientHeight=cvs.offsetHeight;cvs.width=W*DPR;cvs.height=H*DPR;ctx.setTransform(DPR,0,0,DPR,0,0)}
  window.addEventListener('resize',resize,{passive:true}); resize();
  function r(a,b){return a+Math.random()*(b-a)}
  for(let i=0;i<N;i++)parts.push({x:r(0,W),y:r(0,H*.9),vx:r(-.2,.2),vy:r(-.1,.1),r:r(1,2.4),a:r(.2,.8)});
  (function step(){ctx.clearRect(0,0,W,H);for(const p of parts){p.x+=p.vx;p.y+=p.vy;if(p.x<0||p.x>W)p.vx*=-1;if(p.y<0||p.y>H)p.vy*=-1;ctx.beginPath();ctx.arc(p.x,p.y,p.r,0,Math.PI*2);ctx.fillStyle=`rgba(80,80,120,${p.a})`;ctx.fill()}
  for(let i=0;i<parts.length;i++)for(let j=i+1;j<parts.length;j++){const a=parts[i],b=parts[j],d=Math.hypot(a.x-b.x,a.y-b.y);if(d<90){ctx.strokeStyle='rgba(60,60,120,.06)';ctx.lineWidth=1;ctx.beginPath();ctx.moveTo(a.x,a.y);ctx.lineTo(b.x,b.y);ctx.stroke()}}requestAnimationFrame(step)})();
})();

/* 研究宣言：静态起伏 */
(function(){
  const p=document.getElementById('rqText'); if(!p) return;
  const words=p.textContent.trim().split(/\s+/);
  p.innerHTML=words.map(w=>`<span class="w">${w}</span>`).join(' ');
  p.querySelectorAll('.w').forEach((s,i)=>{ s.style.transform=`translateY(${Math.sin(i*0.4)*3}px)`; });
})();

/* Lightbox */
const lb=document.getElementById('lb'), lbImg=document.getElementById('lb-img');
document.querySelectorAll('[data-lightbox]').forEach(el=>el.addEventListener('click',()=>{lbImg.src=el.getAttribute('data-lightbox');lb.setAttribute('data-open','true')}))
lb.addEventListener('click',e=>{if(e.target===lb||e.target.classList.contains('close'))lb.removeAttribute('data-open')});
document.addEventListener('keydown',e=>{if(e.key==='Escape')lb.removeAttribute('data-open')});

/* ===== Future Map：流线科技感（发光节点 + 渐变曲线 + Tooltip） ===== */
(function(){
  const wrap=document.getElementById('future-map'); if(!wrap) return;
  const tip=document.getElementById('future-tip');
  const cv=document.getElementById('futureCanvas'), ctx=cv.getContext('2d');
  let DPR=Math.min(window.devicePixelRatio||1,2);
  function size(){const r=wrap.getBoundingClientRect(); cv.width=r.width*DPR; cv.height=r.height*DPR; cv.style.width=r.width+'px'; cv.style.height=r.height+'px'; ctx.setTransform(DPR,0,0,DPR,0,0)}
  window.addEventListener('resize', size, {passive:true}); size();

  const nodes=[
    {id:0,label:'Sparse Activation',desc:'Build routing/gating modules that mimic cortical sparsity (top-k, Hebbian-like updates) to keep perception efficient while preserving affect discriminability.'},
    {id:1,label:'Efficient Decision',desc:'Amortized tree search + model-based RL under cognitive constraints (limited WM, bounded rationality) for stable HCI reasoning.'},
    {id:2,label:'Ling-MCP',desc:'Memory-constrained planning with rolling summaries; reset policies for stability.'},
    {id:3,label:'Ling-CoT',desc:'Evolutionary mutation/selection to harden chains-of-thought against prompt/polarity shifts.'},
    {id:4,label:'HCI · evo-loops',desc:'Interactive tutoring & co-creation; affect-aware feedback (explain, nudge, re-plan).'},
    {id:5,label:'Agents',desc:'Tool-use pipelines with self-reflection checkpoints integrating affect cues.'},
    {id:6,label:'Layer Probing',desc:'Representation surgery + causal mediation to map appraisal/valence loci.'},
    {id:7,label:'ChineseEEG-2',desc:'Bilingual speech↔listening dataset; MNE-Python preprocessing and reproducible splits.'},
    {id:8,label:'NCC Pipelines',desc:'EEG/MEG pipelines, deterministic eval harness, stress-tests for valence flips.'},
    {id:9,label:'Seed-V / OCR',desc:'VL preprocessing & document understanding foundation for affect-aware QA.'},
    {id:10,label:'Amygdala-gate',desc:'Single-turn discrete gating prior prioritizing salient events without rumination.'},
  ];
  const edges=[[0,1],[0,2],[2,3],[1,4],[4,5],[5,6],[4,8],[7,8],[8,9],[5,10],[0,6],[6,2],[3,6],[1,10]];

  // 初始化位置
  function rand(a,b){return a+Math.random()*(b-a)}
  const pad=36;
  nodes.forEach(n=>{n.x=rand(pad, cv.width/DPR-pad); n.y=rand(pad, cv.height/DPR-pad); n.vx=0; n.vy=0;});
  const targetLen=120, k=0.05, damp=0.9, rep=1400;

  function force(){
    // 斥力
    for(let i=0;i<nodes.length;i++) for(let j=i+1;j<nodes.length;j++){
      const a=nodes[i], b=nodes[j]; let dx=a.x-b.x, dy=a.y-b.y; let d=Math.hypot(dx,dy)+0.01;
      const F=rep/(d*d); dx/=d; dy/=d; a.vx+=dx*F; a.vy+=dy*F; b.vx-=dx*F; b.vy-=dy*F;
    }
    // 弹簧
    for(const [i,j] of edges){
      const a=nodes[i], b=nodes[j]; let dx=b.x-a.x, dy=b.y-a.y; let d=Math.hypot(dx,dy)+0.01;
      const F=k*(d-targetLen); dx/=d; dy/=d; a.vx+=dx*F; a.vy+=dy*F; b.vx-=dx*F; b.vy-=dy*F;
    }
    // 边界
    for(const n of nodes){
      n.vx*=damp; n.vy*=damp; n.x+=n.vx; n.y+=n.vy;
      if(n.x<pad){n.x=pad;n.vx*=-.6} if(n.x>cv.width/DPR-pad){n.x=cv.width/DPR-pad;n.vx*=-.6}
      if(n.y<pad){n.y=pad;n.vy*=-.6} if(n.y>cv.height/DPR-pad){n.y=cv.height/DPR-pad;n.vy*=-.6}
    }
  }

  let hover=null;
  function draw(){
    ctx.clearRect(0,0,cv.width/DPR,cv.height/DPR);
    force();

    // 流线曲边
    const t=Date.now()/1200;
    for(const [i,j] of edges){
      const a=nodes[i], b=nodes[j];
      const mx=(a.x+b.x)/2, my=(a.y+b.y)/2;
      const dx=b.x-a.x, dy=b.y-a.y, d=Math.hypot(dx,dy);
      const nx=-dy/d, ny=dx/d; // 法线
      const bend = Math.min(26, 8 + d/12);                    // 弯曲幅度
      const cx=mx+nx*bend, cy=my+ny*bend;                     // 控制点
      const grad=ctx.createLinearGradient(a.x,a.y,b.x,b.y);
      grad.addColorStop(0,'rgba(96,165,250,.55)');
      grad.addColorStop(.5,'rgba(167,139,250,.45)');
      grad.addColorStop(1,'rgba(236,72,153,.38)');

      ctx.lineWidth = 1.6;
      ctx.strokeStyle = grad;
      ctx.beginPath();
      ctx.moveTo(a.x,a.y);
      ctx.quadraticCurveTo(cx,cy,b.x,b.y);
      ctx.stroke();

      // 轻微“流动”高光
      const p = (Math.sin(t+ i*1.7)+1)/2; // 0..1
      const hx = a.x*(1-p) + b.x*p, hy = a.y*(1-p) + b.y*p;
      const g2=ctx.createRadialGradient(hx,hy,0,hx,hy,20);
      g2.addColorStop(0,'rgba(99,102,241,.25)'); g2.addColorStop(1,'rgba(99,102,241,0)');
      ctx.fillStyle=g2; ctx.beginPath(); ctx.arc(hx,hy,18,0,Math.PI*2); ctx.fill();
    }

    // 节点（发光）
    for(const n of nodes){
      const glow=ctx.createRadialGradient(n.x,n.y,0,n.x,n.y,22);
      glow.addColorStop(0,'rgba(99,102,241,.35)'); glow.addColorStop(1,'rgba(99,102,241,0)');
      ctx.fillStyle=glow; ctx.beginPath(); ctx.arc(n.x,n.y,22,0,Math.PI*2); ctx.fill();

      const fill=ctx.createLinearGradient(n.x-10,n.y-10,n.x+10,n.y+10);
      fill.addColorStop(0,'#60a5fa'); fill.addColorStop(1,'#a78bfa');
      ctx.fillStyle=fill; ctx.beginPath(); ctx.arc(n.x,n.y,(hover===n?7:5),0,Math.PI*2); ctx.fill();

      ctx.font='600 12.5px Inter, ui-sans-serif'; ctx.fillStyle='#1f2937';
      ctx.textAlign='center'; ctx.fillText(n.label, n.x, n.y-14);
    }
    requestAnimationFrame(draw);
  }
  draw();

  function hit(x,y){ for(const n of nodes){ if(Math.hypot(x-n.x,y-n.y)<=10) return n; } return null; }
  cv.addEventListener('mousemove',e=>{
    const r=cv.getBoundingClientRect(); const x=e.clientX-r.left, y=e.clientY-r.top;
    hover=hit(x,y);
    if(hover){
      tip.style.display='block'; tip.innerText=hover.desc;
      const tw=tip.offsetWidth, th=tip.offsetHeight;
      let tx=x+16, ty=y+16; if(tx+tw>r.width) tx=x-tw-16; if(ty+th>r.height) ty=y-th-16;
      tip.style.transform=`translate(${tx}px,${ty}px)`;
    }else tip.style.display='none';
  });
})();
</script>
</body>
</html>
